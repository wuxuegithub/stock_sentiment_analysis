{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.1.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: numpy in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: requests in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Collecting tokenizers==0.9.4\n",
      "  Using cached tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2020.11.13-cp36-cp36m-manylinux2014_x86_64.whl (723 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.55.2-py2.py3-none-any.whl (68 kB)\n",
      "Collecting dataclasses\n",
      "  Using cached dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-20.8-py2.py3-none-any.whl (39 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from requests->transformers) (1.26.2)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.43-py3-none-any.whl\n",
      "Requirement already satisfied: click in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.0.0-py3-none-any.whl (302 kB)\n",
      "Installing collected packages: tqdm, regex, pyparsing, joblib, tokenizers, sacremoses, packaging, filelock, dataclasses, transformers\n",
      "Successfully installed dataclasses-0.8 filelock-3.0.12 joblib-1.0.0 packaging-20.8 pyparsing-2.4.7 regex-2020.11.13 sacremoses-0.0.43 tokenizers-0.9.4 tqdm-4.55.2 transformers-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.8.2-cp36-cp36m-manylinux1_x86_64.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /userhome/30/xwu/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from torchvision) (1.19.5)\n",
      "Collecting torch==1.7.1\n",
      "  Downloading torch-1.7.1-cp36-cp36m-manylinux1_x86_64.whl (776.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 776.8 MB 26 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /userhome/30/xwu/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from torch==1.7.1->torchvision) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /userhome/30/xwu/anaconda3/envs/tensorflow/lib/python3.6/site-packages (from torch==1.7.1->torchvision) (0.8)\n",
      "Collecting pillow>=4.1.1\n",
      "  Downloading Pillow-8.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n",
      "Successfully installed pillow-8.1.0 torch-1.7.1 torchvision-0.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.3.3-cp36-cp36m-manylinux1_x86_64.whl (11.6 MB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from matplotlib) (1.19.2)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-8.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Installing collected packages: pillow, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.3 pillow-8.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow                         2.4.0     \n",
      "tensorflow-estimator               2.4.0     \n",
      "tensorflow-gpu                     2.4.0     \n",
      "transformers                       4.1.1     \n"
     ]
    }
   ],
   "source": [
    "!pip list | grep \"tensorflow\"   # Check tensorflow==2.0.0, tensorflow-gpu==2.0.0\n",
    "!pip list | grep \"transformers\" # Check transformers>=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.24.0-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from scikit-learn) (1.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from scikit-learn) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from scikit-learn) (1.19.2)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-0.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "dir_name= os.getcwd()+'/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  2307      \n",
      "=================================================================\n",
      "Total params: 109,484,547\n",
      "Trainable params: 109,484,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification,TFBertModel\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=3)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nasdaq_files=\"/userhome/cs/wuxue/Sentiment_Analysis/stock_ticker_datasets/nasdaq.csv\"\n",
    "# nyse_files=\"/userhome/cs/wuxue/Sentiment_Analysis/stock_ticker_datasets/nyse.csv\"\n",
    "# nasdaq=pd.read_csv(nasdaq_files) \n",
    "# nyse=pd.read_csv(nyse_files)\n",
    "\n",
    "# nasdaq['Symbol']=nasdaq['Symbol'].astype(str)\n",
    "# nasdaq_input=nasdaq['Symbol']\n",
    "\n",
    "# nyse['Symbol']=nyse['Symbol'].astype(str)\n",
    "# nyse_input=nyse['Symbol']\n",
    "# # 3081\n",
    "# n = 100  #chunk row size\n",
    "# nasdaq_df = [nasdaq_input[i:i+n] for i in range(0,nasdaq_input.shape[0],n)]\n",
    "# nyse_df = [nyse_input[i:i+n] for i in range(0,nyse_input.shape[0],n)]\n",
    "# df=nasdaq_df+nyse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# for list in nasdaq_df:\n",
    "#      for name in list:\n",
    "#             try:\n",
    "#                 df_tweets = pd.read_csv('/userhome/cs/wuxue/Sentiment_Analysis/data-tweets/data-$%s-tweets.csv'%name ,names=['dates','tweets'],index_col='dates')\n",
    "#                 df_dates=pd.read_csv('/userhome/cs/wuxue/Sentiment_Analysis/stock_label/data-%s-label.csv'%name,names=['dates','label'],index_col='dates')\n",
    "\n",
    "#                 merge=pd.merge(df_tweets,df_dates, how='inner', left_index=True, right_index=True)\n",
    "#                 df=df.append(merge)\n",
    "                \n",
    "#             except:\n",
    "#                 print('no such file exist')\n",
    "#                 pass\n",
    "# df.to_csv('labelled_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_tweets(name):\n",
    "   \n",
    "    print('reading tweets..')\n",
    "    \n",
    "    df = pd.read_csv(name)\n",
    "    print(df)\n",
    "\n",
    "    df = df.drop(['Unnamed: 0','dates','ticker','compound_vader_score'],axis=1)\n",
    "    df=df.reset_index(drop=True)\n",
    "    df=df.dropna()\n",
    "    \n",
    "    possible_labels = df.pred_label.unique()\n",
    "    label_dict = {}\n",
    "    for index, possible_label in enumerate(possible_labels):\n",
    "        label_dict[possible_label] = index\n",
    "    \n",
    "    df['label'] = df.label.replace(label_dict)\n",
    "    df['pred_label'] = df.pred_label.replace(label_dict)\n",
    "    x_train,y_train=train_test_split(df,test_size=0.2,random_state=0,stratify=df.pred_label.values)\n",
    "#     print(x_train)\n",
    "    return x_train,y_train\n",
    "# read_tweets('nasdaq_labelled_tweets.csv')\n",
    "\n",
    "def read_news(name):\n",
    "    print('reading news..')\n",
    "    \n",
    "    df = pd.read_csv(name)\n",
    "    print(df)\n",
    "   \n",
    "    df = df.drop(['Unnamed: 0','dates','ticker','compound_vader_score'],axis=1)\n",
    "    df=df.reset_index(drop=True)\n",
    "    df=df.dropna()\n",
    "#     label_dict = {0:1,1:2,2:3}\n",
    "    possible_labels = df.pred_label.unique()\n",
    "    label_dict = {}\n",
    "    for index, possible_label in enumerate(possible_labels):\n",
    "        label_dict[possible_label] = index\n",
    "    print(label_dict)\n",
    "\n",
    "    df['pred_label'] = df.pred_label.replace(label_dict)\n",
    "    x_train,y_train=train_test_split(df,\n",
    "                                     test_size=0.2,\n",
    "                                     random_state=0,\n",
    "                                     stratify=df.pred_label.values)\n",
    "#     print(x_train)\n",
    "    return x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN):\n",
    "    print('converting data')\n",
    "    \n",
    "    train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "    validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "  \n",
    "    return train_InputExamples, validation_InputExamples\n",
    "\n",
    "# train_InputExamples, validation_InputExamples = convert_data_to_examples(x_train,  y_train, 'tweets_x', 'tweets_y')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    print('converting examples to tf_datasets')\n",
    "    features = [] # -> will hold InputFeatures to be converted later\n",
    "    \n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length, # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "    def gen():\n",
    "        \n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(file_name):\n",
    "    print('model training')\n",
    "    x_train,y_train=read_tweets(file_name)    \n",
    "\n",
    "    train_InputExamples, validation_InputExamples = convert_data_to_examples(x_train, y_train, 'tweets', 'pred_label')\n",
    "#     print(train_InputExamples)\n",
    "#     train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "    train_data = convert_examples_to_tf_dataset(train_InputExamples.values.tolist(), tokenizer)\n",
    "    print(train_data)\n",
    "    train_data = train_data.shuffle(100).batch(15).repeat(2)\n",
    "\n",
    "\n",
    "    validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "#     validation_data = convert_examples_to_tf_dataset(validation_InputExamples.values.tolist(), tokenizer)\n",
    "    validation_data = validation_data.batch(15)\n",
    "    return train_data,validation_data\n",
    "\n",
    "def news_model_train(file_name):\n",
    "    print('model training')\n",
    "    x_train,y_train=read_news(file_name)    \n",
    "\n",
    "    train_InputExamples, validation_InputExamples = convert_data_to_examples(x_train, y_train, 'news', 'pred_label')\n",
    "#     print(train_InputExamples)\n",
    "#     train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "    train_data = convert_examples_to_tf_dataset(train_InputExamples.values.tolist(), tokenizer)\n",
    "    print(train_data)\n",
    "    train_data = train_data.shuffle(100).batch(15).repeat(2)\n",
    "\n",
    "\n",
    "    validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "#     validation_data = convert_examples_to_tf_dataset(validation_InputExamples.values.tolist(), tokenizer)\n",
    "    validation_data = validation_data.batch(15)\n",
    "    return train_data,validation_data\n",
    "# model_train('nasdaq_labelled_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_validation(train_data,validation_data):\n",
    "    print('validation..')\n",
    "#     model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "    \n",
    "\n",
    "    # model.fit(train_data, epochs=2, validation_data=validation_data)\n",
    "    history=model.fit(train_data, epochs=2, validation_data=validation_data)\n",
    "    print(history)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def accuracy_visualization(history):\n",
    "    print('visualization')\n",
    "    loss_train = history.history['accuracy']\n",
    "    loss_train = np.array(loss_train)\n",
    "    loss_val = history.history['val_accuracy']\n",
    "    loss_val=np.array(loss_val)\n",
    "    print(loss_train)\n",
    "    print(loss_val)\n",
    "    epochs=range(1, len(loss_train) + 1)\n",
    "    plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "    plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.ylim(ymax=1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#     date=datetime.now().strftime(\"%Y-%m-%d\")\n",
    "#     path='/userhome/cs/wuxue/Sentiment_Analysis/results/us/nasdaq/'+date+'-validation-graph'\n",
    "    \n",
    "    \n",
    "#     print(trend_path)\n",
    "#     plt.savefig(path)\n",
    "#     print(my_path)\n",
    "    \n",
    "# accuracy_visualization(history,'AACQ')\n",
    " \n",
    "#     with open('/userhome/cs/wuxue/Sentiment_Analysis/data-tweets/'+'data-%s-tweets.csv'%name,'w') as f:\n",
    "#     plt.savefig('foo.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data training\n",
    "def start(file_name):\n",
    "    train_data,validation_data=model_train(file_name)\n",
    "    history=model_validation(train_data,validation_data)\n",
    "    return history\n",
    "    \n",
    "\n",
    "def news_start(file_name):\n",
    "    train_data,validation_data=news_model_train(file_name)\n",
    "    history=model_validation(train_data,validation_data)\n",
    "    return history\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n",
      "reading tweets..\n",
      "       Unnamed: 0       dates ticker  compound_vader_score  pred_label  \\\n",
      "0               0  2020-12-26   ABCL              0.778300           2   \n",
      "1               1  2020-12-26   ABEO              0.226300           2   \n",
      "2               2  2020-12-26   ABUS              0.361200           2   \n",
      "3               3  2020-12-26   ACHV              0.541300           2   \n",
      "4               4  2020-12-26    ADP              0.000000           1   \n",
      "...           ...         ...    ...                   ...         ...   \n",
      "23744       23744  2021-01-08     ZS              0.178829           2   \n",
      "23745       23745  2021-01-08   ZSAN              0.087868           2   \n",
      "23746       23746  2021-01-08   ZUMZ              0.000000           1   \n",
      "23747       23747  2021-01-08   ZYNE              0.000000           1   \n",
      "23748       23748  2021-01-08   ZYXI              0.074583           2   \n",
      "\n",
      "                                                  tweets  \n",
      "0      b'RT @TradezTiger: Why Investors Like $CBBT? \\...  \n",
      "1      b'RT @TradezTiger: Why Investors Like $CBBT? \\...  \n",
      "2      b'RT @TradezTiger: Why Investors Like $CBBT? \\...  \n",
      "3      b'RT @TradezTiger: Why Investors Like $CBBT? \\...  \n",
      "4      b'RT @TradezTiger: Why Investors Like $CBBT? \\...  \n",
      "...                                                  ...  \n",
      "23744  b'@sentivcapital Same here, $AMRN was my bigge...  \n",
      "23745  b'@sentivcapital @juliaskripkaser @buysidebio ...  \n",
      "23746  b\"$ARPO Cool basic science + some clinical val...  \n",
      "23747  b\"FREE TRIAL\\nSign up and be ready to receive ...  \n",
      "23748  b'$ARPO  My average is $0.982 https://t.co/Beu...  \n",
      "\n",
      "[23749 rows x 6 columns]\n",
      "converting data\n",
      "converting examples to tf_datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FlatMapDataset shapes: ({input_ids: (None,), attention_mask: (None,), token_type_ids: (None,)}, ()), types: ({input_ids: tf.int32, attention_mask: tf.int32, token_type_ids: tf.int32}, tf.int64)>\n",
      "converting examples to tf_datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation..\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1188/Unknown - 677s 570ms/step - loss: nan - accuracy: 0.6437"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 707s 595ms/step - loss: nan - accuracy: 0.6437 - val_loss: nan - val_accuracy: 0.6436\n",
      "Epoch 2/2\n",
      "1188/1188 [==============================] - 598s 503ms/step - loss: nan - accuracy: 0.6437 - val_loss: nan - val_accuracy: 0.6436\n",
      "<tensorflow.python.keras.callbacks.History object at 0x145a0a5d7e80>\n"
     ]
    }
   ],
   "source": [
    "nasdaq_vader_tweets_path=os.path.join(dir_name,'train-data/nasdaq/nasdaq_vader_tweets.csv')\n",
    "nasdaq_tweets_history=start(nasdaq_vader_tweets_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visualization\n",
      "[0.64366543 0.64366543]\n",
      "[0.64357895 0.64357895]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_visualization(nasdaq_tweets_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n",
      "reading news..\n",
      "       Unnamed: 0       dates ticker  compound_vader_score  pred_label  \\\n",
      "0               0     01:00AM   PRCP              0.663300           2   \n",
      "1               1     01:00PM   HYAC              0.670500           2   \n",
      "2               2     01:03PM   RELV             -0.361200           0   \n",
      "3               3     01:05PM  GLIBA              0.745600           2   \n",
      "4               4     01:08PM   DXLG              0.510600           2   \n",
      "...           ...         ...    ...                   ...         ...   \n",
      "92144       92144  2021-01-11     YY              0.080133           2   \n",
      "92145       92145  2021-01-11   ZCMD              0.051600           2   \n",
      "92146       92146  2021-01-11     ZM              0.636900           2   \n",
      "92147       92147  2021-01-11     ZS              0.340000           2   \n",
      "92148       92148  2021-01-11   ZUMZ              0.401900           2   \n",
      "\n",
      "                                                    news  \n",
      "0      ATA Creativity Global Reports 2020 Third Quart...  \n",
      "1      ATA Creativity Global Schedules 2020 Third Qua...  \n",
      "2      ATA Creativity Global Reports 2020 Second Quar...  \n",
      "3      ATA Creativity Global Schedules 2020 Second Qu...  \n",
      "4      ATA Creativity Global Regains Compliance with ...  \n",
      "...                                                  ...  \n",
      "92144  Scholar Rock Reports Third Quarter 2020 Financ...  \n",
      "92145  2 Top Biotech Stocks From the IPO Class of 201...  \n",
      "92146  Scholar Rock Announces Closing of Public Offer...  \n",
      "92147  Biotech Stock Roundup: GILD's Veklury Approved...  \n",
      "92148  Scholar Rock Announces Positive Proof-of-Conce...  \n",
      "\n",
      "[92149 rows x 6 columns]\n",
      "{2: 0, 0: 1, 1: 2}\n",
      "converting data\n",
      "converting examples to tf_datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FlatMapDataset shapes: ({input_ids: (None,), attention_mask: (None,), token_type_ids: (None,)}, ()), types: ({input_ids: tf.int32, attention_mask: tf.int32, token_type_ids: tf.int32}, tf.int64)>\n",
      "converting examples to tf_datasets\n",
      "validation..\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x14f2e16420b0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x14f2e0355b38> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x14f2e16420b0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x14f2e0355b38> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4115/Unknown - 1138s 277ms/step - loss: 0.4907 - accuracy: 0.8175"
     ]
    }
   ],
   "source": [
    "nasdaq_vader_news_path=os.path.join(dir_name,'train-data/nasdaq/nasdaq_vader_news.csv')\n",
    "    \n",
    "nasdaq_news_history=news_start(nasdaq_vader_news_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_visualization(nasdaq_news_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nyse_vader_news_path=os.path.join(dir_name,'train-data/nyse/nyse_vader_news.csv')\n",
    "nyse_news_history=news_start(nyse_vader_news_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_visualization(nyse_news_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_vader_tweets_path=os.path.join(dir_name,'train-data/nyse/nyse_vader_tweets.csv')\n",
    "nyse_tweets_history=start(nyse_vader_tweets_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_visualization(nyse_tweets_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start('nyse_labelled_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n",
      "reading news..\n",
      "      Unnamed: 0       dates  ticker  compound_vader_score  pred_label  \\\n",
      "0              0  2012-10-29   80737                0.0722           1   \n",
      "1              1  2013-04-18    4508               -0.4767          -1   \n",
      "2              2  2013-09-02    5924               -0.4767          -1   \n",
      "3              3  2013-09-03    5924                0.3612           1   \n",
      "4              4  2013-11-21    2951               -0.1280          -1   \n",
      "...          ...         ...     ...                   ...         ...   \n",
      "2073        2073  2021-01-13    1928                0.3182           1   \n",
      "2074        2074  2021-01-13    2282                0.3182           1   \n",
      "2075        2075  2021-01-13    2318               -0.4019          -1   \n",
      "2076        2076  2021-01-13    2800               -0.4404          -1   \n",
      "2077        2077  2021-01-13    9988                0.6249           1   \n",
      "\n",
      "                                                   news  \n",
      "0      HSI Widens Gain to Over 200 Pts, Nearly 1-Yr ...  \n",
      "1      <Research Report>G Sachs Boosts CKH HOLDINGS ...  \n",
      "2      *G Sachs Boosts CKH HOLDINGS (00001.HK) TP to...  \n",
      "3        《HKEx》- 00001 CKH HOLDINGS - MONTHLY RETURN...  \n",
      "4      <Outlook>G Sachs, M Stanley's HK Stock Top Pi...  \n",
      "...                                                 ...  \n",
      "2073     《HKEx》- 03798 HOMELAND ITL - Monthly Return...  \n",
      "2074     《HKEx》- 03799 DALI FOODS - Monthly Return o...  \n",
      "2075     《HKEx》- 03799 DALI FOODS - Monthly Return o...  \n",
      "2076     《HKEx》- 03799 DALI FOODS - Monthly Return o...  \n",
      "2077     《HKEx》- 03799 DALI FOODS - Monthly Return o...  \n",
      "\n",
      "[2078 rows x 6 columns]\n",
      "{1: 0, -1: 1, 0: 2}\n",
      "converting data\n",
      "converting examples to tf_datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/30/xwu/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FlatMapDataset shapes: ({input_ids: (None,), attention_mask: (None,), token_type_ids: (None,)}, ()), types: ({input_ids: tf.int32, attention_mask: tf.int32, token_type_ids: tf.int32}, tf.int64)>\n",
      "converting examples to tf_datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation..\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    260/Unknown - 121s 467ms/step - loss: nan - accuracy: 0.8929"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 127s 488ms/step - loss: nan - accuracy: 0.8929 - val_loss: nan - val_accuracy: 0.8942\n",
      "Epoch 2/5\n",
      "260/260 [==============================] - 127s 487ms/step - loss: nan - accuracy: 0.8929 - val_loss: nan - val_accuracy: 0.8942\n",
      "Epoch 3/5\n",
      "260/260 [==============================] - 128s 494ms/step - loss: nan - accuracy: 0.8929 - val_loss: nan - val_accuracy: 0.8942\n",
      "Epoch 4/5\n",
      "260/260 [==============================] - 128s 494ms/step - loss: nan - accuracy: 0.8929 - val_loss: nan - val_accuracy: 0.8942\n",
      "Epoch 5/5\n",
      "260/260 [==============================] - 128s 493ms/step - loss: nan - accuracy: 0.8929 - val_loss: nan - val_accuracy: 0.8942\n",
      "<tensorflow.python.keras.callbacks.History object at 0x145a15e60630>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hkex_news_history=os.path.join(dir_name,'train-data/hkex/hkex_vader_news.csv')\n",
    "hkex_news_history=news_start(hkex_news_history)\n",
    "\n",
    "# hkex_news_history=news_start('hkex_labelled_news.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visualization\n",
      "[0.89290011 0.89290011 0.89290011 0.89290011 0.89290011]\n",
      "[0.89423078 0.89423078 0.89423078 0.89423078 0.89423078]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_visualization(hkex_news_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# create folder\n",
    "# for list in df:\n",
    "#     for name in list:\n",
    "#         try:  \n",
    "#             path='/userhome/cs/wuxue/Sentiment_Analysis/results/us/'+str(name)+'/trends'\n",
    "#             os.mkdir(path)  \n",
    "#         except OSError as error:  \n",
    "#             print(error)  \n",
    "# df = pd.DataFrame(columns = ['dates' , 'tweets', 'label'])\n",
    "# for list in nasdaq_df:\n",
    "#      for name in list:\n",
    "#             try:\n",
    "#                 df_tweets = pd.read_csv('/userhome/cs/wuxue/Sentiment_Analysis/data-tweets/data-$%s-tweets.csv'%name ,names=['dates','tweets'],index_col='dates')\n",
    "#                 df_dates=pd.read_csv('/userhome/cs/wuxue/Sentiment_Analysis/stock_label/data-%s-label.csv'%name,names=['dates','label'],index_col='dates')\n",
    "\n",
    "#                 merge=pd.merge(df_tweets,df_dates, how='inner', left_index=True, right_index=True)\n",
    "#                 df=df.append(merge)\n",
    "                \n",
    "#             except:\n",
    "#                 print('no such file exist')\n",
    "#                 pass\n",
    "# df.to_csv('labelled_tweets.csv')\n",
    "\n",
    "    # merge.reset_index(drop=True)\n",
    "    # x, y = merge.iloc[:, :-1], merge.iloc[:, [-1]]\n",
    "\n",
    "    # df=merge.drop('dates',axis=1)\n",
    "           \n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_sentences = ['This was an awesome movie. I watch it twice my time watching this beautiful movie if I have known it was this good',\n",
    "#                   'One of the worst movies of all time. I cannot believe I wasted two hours of my life for this movie']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statistics \n",
    "# from statistics import mode\n",
    "# from datetime import datetime\n",
    "\n",
    "# def trends(ticker):\n",
    "#     df_tweets = pd.read_csv('/userhome/cs/wuxue/Sentiment_Analysis/data-tweets/data-$%s-tweets.csv'%ticker ,names=['dates','tweets'],index_col='dates')\n",
    "#     df_dates=pd.read_csv('/userhome/cs/wuxue/Sentiment_Analysis/stock_label/data-%s-label.csv'%ticker,names=['dates','label'],index_col='dates')\n",
    "\n",
    "#     merge=pd.merge(df_tweets,df_dates, how='inner', left_index=True, right_index=True)\n",
    "#     tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "#     tf_outputs = model(tf_batch)\n",
    "    \n",
    "#     tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "\n",
    "#     labels = ['Negative','neutral','Positive']\n",
    "#     label = tf.argmax(tf_predictions, axis=1)\n",
    "\n",
    "#     label = label.numpy()\n",
    "#     trend=labels[mode(label)]\n",
    "#     trend_path='/userhome/cs/wuxue/Sentiment_Analysis/results/us/'+ticker+'/trends/'+'trend-'+ticker+'.csv'\n",
    "#      with open(trend_path,'w') as f:\n",
    "#             writer = csv.writer(f)\n",
    "#             date=datetime.now().strftime(\"%Y-%m-%d\")\n",
    "#             writer.writerow([date,trend])\n",
    "\n",
    "        # print(mode(label))\n",
    "# for i in range(len(pred_sentences)):\n",
    "#     output.append()\n",
    "#     print(pred_sentences[i], \": \\n\", labels[label[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
